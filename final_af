import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.svm import SVR
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Load your data
file_path = r'svm-main/BTM_hourlyy.csv'
df = pd.read_csv(file_path)

# Handle non-numeric values
df = df.apply(pd.to_numeric, errors='coerce')

# Impute missing values with mean
imputer = SimpleImputer(strategy='mean')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

# Select features and target variable
X = df_imputed.drop("PM2.5", axis=1)
y = df_imputed["PM2.5"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fine-tuning hyperparameters
param_grid = {
    'C': [8.5, 8.7, 8.9, 9.1, 9.3],
    'kernel': ['rbf'],
    'gamma': [0.0002, 0.00025, 0.0003]
}
svr = SVR()
randomized_search = RandomizedSearchCV(estimator=svr, param_distributions=param_grid, cv=3, scoring='neg_mean_squared_error', n_iter=10, n_jobs=-1)
randomized_search.fit(X_train, y_train)
best_params = randomized_search.best_params_
best_svr = randomized_search.best_estimator_
selector = SelectKBest(score_func=f_regression, k=10)  # Adjust k as needed
X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)
svr_model = SVR(**best_params)
gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
svr_model.fit(X_train_selected, y_train)
gb_model.fit(X_train_selected, y_train)
rf_model.fit(X_train_selected, y_train)
svr_preds = svr_model.predict(X_test_selected)
gb_preds = gb_model.predict(X_test_selected)
rf_preds = rf_model.predict(X_test_selected)
ensemble_preds = (svr_preds + gb_preds + rf_preds) / 3
ensemble_mse = mean_squared_error(y_test, ensemble_preds)
ensemble_rmse = np.sqrt(ensemble_mse)
print(f"SVR Mean Squared Error (MSE): {ensemble_mse}")
print(f"SVR Root Mean Squared Error (RMSE): {ensemble_rmse}")
from sklearn.metrics import r2_score


# Calculate R^2 score for SVR model
svr_r2 = r2_score(y_test, ensemble_preds)

print(f"SVR R^2 Score: {svr_r2}")
